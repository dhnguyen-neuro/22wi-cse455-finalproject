{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport torch\nimport torchvision\nfrom torchvision import transforms, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport sklearn\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:15:32.453419Z","iopub.execute_input":"2022-03-17T02:15:32.45443Z","iopub.status.idle":"2022-03-17T02:15:40.207473Z","shell.execute_reply.started":"2022-03-17T02:15:32.454319Z","shell.execute_reply":"2022-03-17T02:15:40.20621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define constants\nN_CLASS = 555\nBATCH_SIZE = 128\nIM_SIZE = 256\nIM_PADDING = 16\nVAL_SPLIT = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:15:40.20948Z","iopub.execute_input":"2022-03-17T02:15:40.20972Z","iopub.status.idle":"2022-03-17T02:15:40.214589Z","shell.execute_reply.started":"2022-03-17T02:15:40.209689Z","shell.execute_reply":"2022-03-17T02:15:40.213571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clean and format data","metadata":{}},{"cell_type":"code","source":"def get_bird128_data():\n    transform_train = transforms.Compose([\n        transforms.Resize(IM_SIZE),\n        transforms.RandomCrop(IM_SIZE, padding=IM_PADDING, padding_mode='edge'), \n        transforms.RandomHorizontalFlip(),    # Flip 50% of images along y-axis\n        transforms.ToTensor(),\n        transforms.Normalize(0, 1)\n    ])\n    \n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(0, 1)\n    ])\n    \n    trainset = torchvision.datasets.ImageFolder(root='../input/birds-22wi/birds/train/', transform=transform_train)\n    testset = torchvision.datasets.ImageFolder(root='../input/birds-22wi/birds/test/', transform=transform_test)\n    \n    n = len(trainset)\n    indices = list(range(n))\n    np.random.shuffle(indices)\n    split_idx = int(np.floor(VAL_SPLIT * n))\n    \n    train_indices = indices[split_idx:]\n    val_indices = indices[:split_idx]\n    \n    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n    \n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n    valloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    \n    return {'train': trainloader, 'val': valloader, 'test': testloader}\n\ndata = get_bird128_data()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:15:40.216067Z","iopub.execute_input":"2022-03-17T02:15:40.216332Z","iopub.status.idle":"2022-03-17T02:15:52.514552Z","shell.execute_reply.started":"2022-03-17T02:15:40.216303Z","shell.execute_reply":"2022-03-17T02:15:52.513599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(iter(data['train']).next())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:15:52.516238Z","iopub.execute_input":"2022-03-17T02:15:52.516568Z","iopub.status.idle":"2022-03-17T02:16:00.363862Z","shell.execute_reply.started":"2022-03-17T02:15:52.516526Z","shell.execute_reply":"2022-03-17T02:16:00.362853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch = next(iter(data['val']))\nprint(test_batch)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:00.366791Z","iopub.execute_input":"2022-03-17T02:16:00.367067Z","iopub.status.idle":"2022-03-17T02:16:07.789373Z","shell.execute_reply.started":"2022-03-17T02:16:00.367034Z","shell.execute_reply":"2022-03-17T02:16:07.788091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(data['train'])\nimages, labels = dataiter.next()\nimages = images[:8]\nprint(images.size())\n\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(\"Labels:\" + ' '.join('%9s' % labels[j] for j in range(8)))\n\nflat = torch.flatten(images, 1)\nprint(images.size())\nprint(flat.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:07.79142Z","iopub.execute_input":"2022-03-17T02:16:07.792098Z","iopub.status.idle":"2022-03-17T02:16:12.706272Z","shell.execute_reply.started":"2022-03-17T02:16:07.792049Z","shell.execute_reply":"2022-03-17T02:16:12.70445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model setup","metadata":{}},{"cell_type":"code","source":"def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n    net.to(device)\n    net.train()\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n\n    # Load previous training state\n    if state:\n        net.load_state_dict(state['net'])\n        optimizer.load_state_dict(state['optimizer'])\n        start_epoch = state['epoch']\n        losses = state['losses']\n\n  # Fast forward lr schedule through already trained epochs\n    for epoch in range(start_epoch):\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n    for epoch in range(start_epoch, epochs):\n        sum_loss = 0.0\n\n        # Update learning rate when scheduled\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n        for i, batch in enumerate(dataloader, 0):\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()  # autograd magic, computes all the partial derivatives\n            optimizer.step() # takes a step in gradient direction\n\n            losses.append(loss.item())\n            sum_loss += loss.item()\n\n            if i % print_every == print_every-1:    # print every 10 mini-batches\n                if verbose:\n                    print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n                sum_loss = 0.0\n        if checkpoint_path:\n            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n    return losses\n\ndef accuracy(net, dataloader):\n    net.to(device)\n    net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            images, labels = batch[0].to(device), batch[1].to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct/total\n\ndef smooth(x, size):\n    return np.convolve(x, np.ones(size)/size, mode='valid')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:12.712552Z","iopub.execute_input":"2022-03-17T02:16:12.713303Z","iopub.status.idle":"2022-03-17T02:16:12.7422Z","shell.execute_reply.started":"2022-03-17T02:16:12.713246Z","shell.execute_reply":"2022-03-17T02:16:12.740949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50 = models.resnet50(pretrained=True)\nresnext50 = models.resnext50_32x4d(pretrained=True)\nwideresnet50 = models.wide_resnet50_2(pretrained=True)\n\nmodel_dict = {'resnet': resnet50, 'resnext': resnext50, 'wideresnet': wideresnet50}\n\n# Don't update weights other than last layer\nfor model_name in model_dict:\n    model = model_dict[model_name]\n    for param in model.parameters():\n        param.requires_grad = False\n    \n# Replace fully connected layer\n    fc_in = model.fc.in_features\n    model.fc = nn.Linear(fc_in, N_CLASS)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:12.743769Z","iopub.execute_input":"2022-03-17T02:16:12.744977Z","iopub.status.idle":"2022-03-17T02:16:23.983855Z","shell.execute_reply.started":"2022-03-17T02:16:12.744922Z","shell.execute_reply":"2022-03-17T02:16:23.982585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"code","source":"if (not os.path.isdir('./checkpoints/')):\n    os.makedirs('./checkpoints/')\ncheckpoints = './checkpoints/'","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:23.985328Z","iopub.execute_input":"2022-03-17T02:16:23.985579Z","iopub.status.idle":"2022-03-17T02:16:23.990456Z","shell.execute_reply.started":"2022-03-17T02:16:23.98555Z","shell.execute_reply":"2022-03-17T02:16:23.98981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_losses = {}\nfor model_name in model_dict:\n    model_loss = train(model_dict[model_name], data['train'], epochs=10, schedule = {0:.01, 5:.001}, checkpoint_path=checkpoints + model_name)\n    model_losses[model_name] = model_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:16:23.991531Z","iopub.execute_input":"2022-03-17T02:16:23.992278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(smooth(model_losses['resnet'],50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(smooth(model_losses['resnext'],50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(smooth(model_losses['wideresnet'],50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Validation accuracy, resnet: %f\" % accuracy(model_dict['resnet'], data['val']))\nprint(\"Validation accuracy, resnext: %f\" % accuracy(model_dict['resnext'], data['val']))\nprint(\"Validation accuracy, wideresnet: %f\" % accuracy(model_dict['wideresnet'], data['val']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Format for submission","metadata":{}},{"cell_type":"code","source":"def getPredFile(model):\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(0, 1)\n    ])\n    testset = torchvision.datasets.ImageFolder(root='../input/birds-22wi/birds/test/', transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, num_workers=2)\n        \n    f = open(\"submission.csv\", \"w\")\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(testloader, 0):\n            outputs = model(images.to(device))\n            _, predicted = torch.max(outputs.data, 1)\n            fname, _ = testloader.dataset.samples[i]\n            pathname_idx = fname.index('test/0/')\n            fname = 'test/' + fname[pathname_idx + 7:]\n            f.write(\"{}, {}\\n\".format(fname, predicted.item()))\n    f.close()\n\ngetPredFile(model_dict['resnet'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}